{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import pickle"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import os\n", "import re\n", "import numpy as np\n", "import pandas as pd\n", "from torch.utils.data import DataLoader, Dataset"]}, {"cell_type": "markdown", "metadata": {}, "source": ["35 attributes which contains enough non-values"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["attributes = [\n", "    \"DiasABP\",\n", "    \"HR\",\n", "    \"Na\",\n", "    \"Lactate\",\n", "    \"NIDiasABP\",\n", "    \"PaO2\",\n", "    \"WBC\",\n", "    \"pH\",\n", "    \"Albumin\",\n", "    \"ALT\",\n", "    \"Glucose\",\n", "    \"SaO2\",\n", "    \"Temp\",\n", "    \"AST\",\n", "    \"Bilirubin\",\n", "    \"HCO3\",\n", "    \"BUN\",\n", "    \"RespRate\",\n", "    \"Mg\",\n", "    \"HCT\",\n", "    \"SysABP\",\n", "    \"FiO2\",\n", "    \"K\",\n", "    \"GCS\",\n", "    \"Cholesterol\",\n", "    \"NISysABP\",\n", "    \"TroponinT\",\n", "    \"MAP\",\n", "    \"TroponinI\",\n", "    \"PaCO2\",\n", "    \"Platelets\",\n", "    \"Urine\",\n", "    \"NIMAP\",\n", "    \"Creatinine\",\n", "    \"ALP\",\n", "]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def extract_hour(x):\n", "    h, _ = map(int, x.split(\":\"))\n", "    return h"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def parse_data(x):\n", "    # extract the last value for each attribute\n", "    x = x.set_index(\"Parameter\").to_dict()[\"Value\"]\n", "    values = []\n", "    for attr in attributes:\n", "        if x.__contains__(attr):\n", "            values.append(x[attr])\n", "        else:\n", "            values.append(np.nan)\n", "    return values"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def parse_id(id_, missing_ratio=0.1):\n", "    data = pd.read_csv(\"./data/physio/set-a/{}.txt\".format(id_))\n", "    # set hour\n", "    data[\"Time\"] = data[\"Time\"].apply(lambda x: extract_hour(x))\n\n", "    # create data for 48 hours x 35 attributes\n", "    observed_values = []\n", "    for h in range(48):\n", "        observed_values.append(parse_data(data[data[\"Time\"] == h]))\n", "    observed_values = np.array(observed_values)\n", "    observed_masks = ~np.isnan(observed_values)\n\n", "    # randomly set some percentage as ground-truth\n", "    masks = observed_masks.reshape(-1).copy()\n", "    obs_indices = np.where(masks)[0].tolist()\n", "    miss_indices = np.random.choice(\n", "        obs_indices, (int)(len(obs_indices) * missing_ratio), replace=False\n", "    )\n", "    masks[miss_indices] = False\n", "    gt_masks = masks.reshape(observed_masks.shape)\n", "    observed_values = np.nan_to_num(observed_values)\n", "    observed_masks = observed_masks.astype(\"float32\")\n", "    gt_masks = gt_masks.astype(\"float32\")\n", "    return observed_values, observed_masks, gt_masks"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def get_idlist():\n", "    patient_id = []\n", "    for filename in os.listdir(\"./data/physio/set-a\"):\n", "        match = re.search(\"\\d{6}\", filename)\n", "        if match:\n", "            patient_id.append(match.group())\n", "    patient_id = np.sort(patient_id)\n", "    return patient_id"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class Physio_Dataset(Dataset):\n", "    def __init__(self, eval_length=48, use_index_list=None, missing_ratio=0.0, seed=0):\n", "        self.eval_length = eval_length\n", "        np.random.seed(seed)  # seed for ground truth choice\n", "        self.observed_values = []\n", "        self.observed_masks = []\n", "        self.gt_masks = []\n", "        path = (\n", "            \"./data/physio_missing\" + str(missing_ratio) + \"_seed\" + str(seed) + \".pk\"\n", "        )\n", "        if os.path.isfile(path):  # if datasetfile is none, create\n", "            idlist = get_idlist()\n", "            for id_ in idlist:\n", "                try:\n", "                    observed_values, observed_masks, gt_masks = parse_id(\n", "                        id_, missing_ratio\n", "                    )\n", "                    self.observed_values.append(observed_values)\n", "                    self.observed_masks.append(observed_masks)\n", "                    self.gt_masks.append(gt_masks)\n", "                except Exception as e:\n", "                    print(id_, e)\n", "                    continue\n", "            self.observed_values = np.array(self.observed_values)\n", "            self.observed_masks = np.array(self.observed_masks)\n", "            self.gt_masks = np.array(self.gt_masks)\n\n", "            # calc mean and std and normalize values\n", "            # (it is the same normalization as Cao et al. (2018) (https://github.com/caow13/BRITS))\n", "            tmp_values = self.observed_values.reshape(-1, 35)\n", "            tmp_masks = self.observed_masks.reshape(-1, 35)\n", "            mean = np.zeros(35)\n", "            std = np.zeros(35)\n", "            for k in range(35):\n", "                c_data = tmp_values[:, k][tmp_masks[:, k] == 1]\n", "                mean[k] = c_data.mean()\n", "                std[k] = c_data.std()\n", "            self.observed_values = (\n", "                (self.observed_values - mean) / std * self.observed_masks\n", "            )\n", "            with open(path, \"wb\") as f:\n", "                pickle.dump(\n", "                    [self.observed_values, self.observed_masks, self.gt_masks], f\n", "                )\n", "        else:  # load datasetfile\n", "            with open(path, \"rb\") as f:\n", "                self.observed_values, self.observed_masks, self.gt_masks = pickle.load(\n", "                    f\n", "                )\n", "        if use_index_list is None:\n", "            self.use_index_list = np.arange(len(self.observed_values))\n", "        else:\n", "            self.use_index_list = use_index_list\n", "    def __getitem__(self, org_index):\n", "        index = self.use_index_list[org_index]\n", "        s = {\n", "            \"observed_data\": self.observed_values[index],\n", "            \"observed_mask\": self.observed_masks[index],\n", "            \"gt_mask\": self.gt_masks[index],\n", "            \"timepoints\": np.arange(self.eval_length),\n", "        }\n", "        return s\n", "    def __len__(self):\n", "        return len(self.use_index_list)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def get_dataloader(seed=1, nfold=None, batch_size=16, missing_ratio=0.1):\n", "    # only to obtain total length of dataset\n", "    dataset = Physio_Dataset(missing_ratio=missing_ratio, seed=seed)\n", "    indlist = np.arange(len(dataset))\n", "    np.random.seed(seed)\n", "    np.random.shuffle(indlist)\n\n", "    # 5-fold test\n", "    start = (int)(nfold * 0.2 * len(dataset))\n", "    end = (int)((nfold + 1) * 0.2 * len(dataset))\n", "    test_index = indlist[start:end]\n", "    remain_index = np.delete(indlist, np.arange(start, end))\n", "    np.random.seed(seed)\n", "    np.random.shuffle(remain_index)\n", "    num_train = (int)(len(dataset) * 0.7)\n", "    train_index = remain_index[:num_train]\n", "    valid_index = remain_index[num_train:]\n", "    dataset = Physio_Dataset(\n", "        use_index_list=train_index, missing_ratio=missing_ratio, seed=seed\n", "    )\n", "    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=1)\n", "    valid_dataset = Physio_Dataset(\n", "        use_index_list=valid_index, missing_ratio=missing_ratio, seed=seed\n", "    )\n", "    valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=0)\n", "    test_dataset = Physio_Dataset(\n", "        use_index_list=test_index, missing_ratio=missing_ratio, seed=seed\n", "    )\n", "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=0)\n", "    return train_loader, valid_loader, test_loader"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}
