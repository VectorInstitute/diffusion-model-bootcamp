{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jul 22 05:38:12 2024       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            On   | 00000000:06:00.0 Off |                    0 |\n",
      "| N/A   47C    P8    17W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "  \n",
    "# TABSYN: Tabular Data Synthesis with Diffusion Models\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduction goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/aieng/diffusion_bootcamp/env/diffusion-models-bootcamp-yasaman-in14eNW_-py3.9/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import src\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from scripts.download_dataset import download_from_uci\n",
    "from scripts.process_dataset import process_data\n",
    "\n",
    "from src.data import preprocess, TabularDataset\n",
    "\n",
    "from src.baselines.tabsyn.pipeline import TabSyn\n",
    "\n",
    "\n",
    "NAME_URL_DICT_UCI = {\n",
    "    \"adult\": \"https://archive.ics.uci.edu/static/public/2/adult.zip\",\n",
    "    \"default\": \"https://archive.ics.uci.edu/static/public/350/default+of+credit+card+clients.zip\",\n",
    "    \"magic\": \"https://archive.ics.uci.edu/static/public/159/magic+gamma+telescope.zip\",\n",
    "    \"shoppers\": \"https://archive.ics.uci.edu/static/public/468/online+shoppers+purchasing+intention+dataset.zip\",\n",
    "    \"beijing\": \"https://archive.ics.uci.edu/static/public/381/beijing+pm2+5+data.zip\",\n",
    "    \"news\": \"https://archive.ics.uci.edu/static/public/332/online+news+popularity.zip\",\n",
    "}\n",
    "\n",
    "DATA_DIR = \"/projects/aieng/diffusion_bootcamp/data/tabular_copy\"\n",
    "RAW_DATA_DIR = f\"{DATA_DIR}/raw_data\"\n",
    "PROCESSED_DATA_DIR = f\"{DATA_DIR}/processed_data\"\n",
    "SYNTH_DATA_DIR = f\"{DATA_DIR}/synthetic_data\"\n",
    "DATA_NAME = \"adult\"\n",
    "\n",
    "MODEL_PATH = f\"/projects/aieng/diffusion_bootcamp/models/tabular/tabsyn_copy\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adult Dataset\n",
    "\n",
    "For more detailed explaination, please refer to the TabDDPM reference implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start processing dataset adult from UCI.\n",
      "Aready downloaded.\n",
      "adult (32561, 15) (16281, 15) (32561, 15)\n",
      "Numerical (32561, 6)\n",
      "Categorical (32561, 8)\n",
      "Processing and Saving adult Successfully!\n",
      "adult\n",
      "Total 48842\n",
      "Train 32561\n",
      "Test 16281\n",
      "Num 6\n",
      "Cat 9\n",
      "\n",
      "============\n",
      "     age          workclass    fnlwgt   education  education.num  \\\n",
      "0  39.0          State-gov   77516.0   Bachelors           13.0   \n",
      "1  50.0   Self-emp-not-inc   83311.0   Bachelors           13.0   \n",
      "2  38.0            Private  215646.0     HS-grad            9.0   \n",
      "3  53.0            Private  234721.0        11th            7.0   \n",
      "4  28.0            Private  338409.0   Bachelors           13.0   \n",
      "\n",
      "        marital.status          occupation    relationship    race      sex  \\\n",
      "0        Never-married        Adm-clerical   Not-in-family   White     Male   \n",
      "1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
      "2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
      "3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
      "4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
      "\n",
      "   capital.gain  capital.loss  hours.per.week  native.country  income  \n",
      "0        2174.0           0.0            40.0   United-States   <=50K  \n",
      "1           0.0           0.0            13.0   United-States   <=50K  \n",
      "2           0.0           0.0            40.0   United-States   <=50K  \n",
      "3           0.0           0.0            40.0   United-States   <=50K  \n",
      "4           0.0           0.0            40.0            Cuba   <=50K   \n",
      "============\n",
      "\n",
      " ? exists in the DataFrame.\n",
      "{'name': 'adult', 'task_type': 'binclass', 'header': None, 'column_names': ['age', 'workclass', 'fnlwgt', 'education', 'education.num', 'marital.status', 'occupation', 'relationship', 'race', 'sex', 'capital.gain', 'capital.loss', 'hours.per.week', 'native.country', 'income'], 'num_col_idx': [0, 2, 4, 10, 11, 12], 'cat_col_idx': [1, 3, 5, 6, 7, 8, 9, 13], 'target_col_idx': [14], 'file_type': 'csv', 'data_path': '/projects/aieng/diffusion_bootcamp/data/tabular/raw_data/adult/adult.data', 'test_path': '/projects/aieng/diffusion_bootcamp/data/tabular/raw_data/adult/adult.test', 'column_info': {'0': {}, 'type': 'categorical', 'max': 99.0, 'min': 1.0, '2': {}, '4': {}, '10': {}, '11': {}, '12': {}, '1': {}, 'categorizes': [' >50K', ' <=50K'], '3': {}, '5': {}, '6': {}, '7': {}, '8': {}, '9': {}, '13': {}, '14': {}}, 'train_num': 32561, 'test_num': 16281, 'idx_mapping': {'0': 0, '1': 6, '2': 1, '3': 7, '4': 2, '5': 8, '6': 9, '7': 10, '8': 11, '9': 12, '10': 3, '11': 4, '12': 5, '13': 13, '14': 14}, 'inverse_idx_mapping': {'0': 0, '6': 1, '1': 2, '7': 3, '2': 4, '8': 5, '9': 6, '10': 7, '11': 8, '12': 9, '3': 10, '4': 11, '5': 12, '13': 13, '14': 14}, 'idx_name_mapping': {'0': 'age', '1': 'workclass', '2': 'fnlwgt', '3': 'education', '4': 'education.num', '5': 'marital.status', '6': 'occupation', '7': 'relationship', '8': 'race', '9': 'sex', '10': 'capital.gain', '11': 'capital.loss', '12': 'hours.per.week', '13': 'native.country', '14': 'income'}, 'metadata': {'columns': {'0': {'sdtype': 'numerical', 'computer_representation': 'Float'}, '2': {'sdtype': 'numerical', 'computer_representation': 'Float'}, '4': {'sdtype': 'numerical', 'computer_representation': 'Float'}, '10': {'sdtype': 'numerical', 'computer_representation': 'Float'}, '11': {'sdtype': 'numerical', 'computer_representation': 'Float'}, '12': {'sdtype': 'numerical', 'computer_representation': 'Float'}, '1': {'sdtype': 'categorical'}, '3': {'sdtype': 'categorical'}, '5': {'sdtype': 'categorical'}, '6': {'sdtype': 'categorical'}, '7': {'sdtype': 'categorical'}, '8': {'sdtype': 'categorical'}, '9': {'sdtype': 'categorical'}, '13': {'sdtype': 'categorical'}, '14': {'sdtype': 'categorical'}}}}\n"
     ]
    }
   ],
   "source": [
    "# download data\n",
    "download_from_uci(DATA_NAME, RAW_DATA_DIR, NAME_URL_DICT_UCI)\n",
    "\n",
    "# process data\n",
    "INFO_DIR = \"data_info\"\n",
    "process_data(DATA_NAME, INFO_DIR, DATA_DIR)\n",
    "\n",
    "# review data\n",
    "df = pd.read_csv(f\"{PROCESSED_DATA_DIR}/{DATA_NAME}/train.csv\")\n",
    "print(\"\\n============\\n\", df.head(5), \"\\n============\\n\")\n",
    "\n",
    "# clean data\n",
    "value = \" ?\"\n",
    "if value in df.values:\n",
    "    print(f\"{value} exists in the DataFrame.\")\n",
    "else:\n",
    "    print(f\"{value} does not exist in the DataFrame.\")\n",
    "\n",
    "# review json file and its contents\n",
    "with open(f\"{PROCESSED_DATA_DIR}/{DATA_NAME}/info.json\", \"r\") as file:\n",
    "    data_info = json.load(file)\n",
    "print(data_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TabSyn Algorithem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation of the algorithm goes here.\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"figures/tabsyn.jpg\" width=\"1000\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'task_type': 'binclass', 'loss_params': {'max_beta': 0.01, 'min_beta': 1e-05, 'lambd': 0.7}, 'model_params': {'vae': {'n_head': 1, 'factor': 32, 'num_layers': 2, 'd_token': 4}}, 'train': {'vae': {'num_epochs': 10, 'batch_size': 4096, 'optim': {'lr': 0.001, 'weight_decay': 0, 'factor': 0.95, 'patience': 10}}, 'diffusion': {'num_epochs': 10, 'batch_size': 4096, 'optim': {'lr': 0.001, 'weight_decay': 0, 'factor': 0.9, 'patience': 20}}}, 'sample': {'steps': 50}}\n"
     ]
    }
   ],
   "source": [
    "config_path = f\"src/baselines/tabsyn/configs/{DATA_NAME}.toml\"\n",
    "raw_config = src.load_config(config_path)\n",
    "\n",
    "print(raw_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_path /projects/aieng/diffusion_bootcamp/data/tabular_copy/processed_data/adult\n",
      "No NaNs in numerical features, skipping\n"
     ]
    }
   ],
   "source": [
    "X_num, X_cat, categories, d_numerical = preprocess(f\"{PROCESSED_DATA_DIR}/{DATA_NAME}\", task_type=raw_config['task_type'])\n",
    "\n",
    "X_train_num, X_test_num = X_num\n",
    "X_train_cat, X_test_cat = X_cat\n",
    "\n",
    "X_train_num, X_test_num = torch.tensor(X_train_num).float(), torch.tensor(X_test_num).float()\n",
    "X_train_cat, X_test_cat =  torch.tensor(X_train_cat), torch.tensor(X_test_cat)\n",
    "\n",
    "train_data = TabularDataset(X_train_num.float(), X_train_cat)\n",
    "\n",
    "# put the test data on the gpu\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "X_test_num = X_test_num.float().to(device)\n",
    "X_test_cat = X_test_cat.to(device)\n",
    "\n",
    "# create the train dataloader\n",
    "train_loader = DataLoader(\n",
    "    train_data,\n",
    "    batch_size = raw_config[\"train\"][\"vae\"][\"batch_size\"],\n",
    "    shuffle = True,\n",
    "    num_workers = 4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset num shape:  torch.Size([32561, 6])\n",
      "test dataset num shape:  torch.Size([16281, 6])\n",
      "train dataset cat shape:  torch.Size([32561, 9])\n",
      "test dataset cat shape:  torch.Size([16281, 9])\n"
     ]
    }
   ],
   "source": [
    "print(\"train dataset num shape: \", train_data.X_num.shape)\n",
    "print(\"test dataset num shape: \", X_test_num.shape)\n",
    "\n",
    "print(\"train dataset cat shape: \", train_data.X_cat.shape)\n",
    "print(\"test dataset cat shape: \", X_test_cat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.category_embeddings.weight.shape=torch.Size([104, 4])\n",
      "self.category_embeddings.weight.shape=torch.Size([104, 4])\n"
     ]
    }
   ],
   "source": [
    "tabsyn = TabSyn(train_loader, X_test_num, X_test_cat, device, num_numerical_features=d_numerical, num_classes=categories)\n",
    "\n",
    "model, pre_encoder, pre_decoder = tabsyn.get_vae_model(**raw_config[\"model_params\"][\"vae\"])\n",
    "\n",
    "optimizer, scheduler = tabsyn.load_optim(model, **raw_config[\"train\"][\"vae\"][\"optim\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model\n",
    "### First Train VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 8/8 [00:02<00:00,  3.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, beta = 0.010000, Train MSE: 11.010106, Train CE:2.190319, Train KL:0.631821, Val MSE:8.316008, Val CE:2.108248, Train ACC:0.277735, Val ACC:0.282088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 8/8 [00:01<00:00,  6.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, beta = 0.010000, Train MSE: 6.690540, Train CE:2.091688, Train KL:0.635280, Val MSE:4.871817, Val CE:2.069340, Train ACC:0.282078, Val ACC:0.284046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 8/8 [00:01<00:00,  6.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2, beta = 0.010000, Train MSE: 3.768258, Train CE:2.027702, Train KL:0.815249, Val MSE:2.518736, Val CE:1.964295, Train ACC:0.319934, Val ACC:0.325082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 8/8 [00:01<00:00,  6.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3, beta = 0.010000, Train MSE: 1.823395, Train CE:1.918054, Train KL:1.096955, Val MSE:1.131964, Val CE:1.863093, Train ACC:0.332476, Val ACC:0.334459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 8/8 [00:01<00:00,  6.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4, beta = 0.010000, Train MSE: 0.834314, Train CE:1.834498, Train KL:1.435878, Val MSE:0.610274, Val CE:1.795356, Train ACC:0.323762, Val ACC:0.324966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 8/8 [00:01<00:00,  6.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5, beta = 0.010000, Train MSE: 0.585323, Train CE:1.734624, Train KL:1.741091, Val MSE:0.586413, Val CE:1.645748, Train ACC:0.340876, Val ACC:0.357158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 8/8 [00:01<00:00,  6.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6, beta = 0.010000, Train MSE: 0.552036, Train CE:1.587937, Train KL:1.955335, Val MSE:0.509859, Val CE:1.511510, Train ACC:0.476644, Val ACC:0.481557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 8/8 [00:01<00:00,  7.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7, beta = 0.010000, Train MSE: 0.470287, Train CE:1.454352, Train KL:2.177709, Val MSE:0.439621, Val CE:1.372933, Train ACC:0.520585, Val ACC:0.522101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 8/8 [00:01<00:00,  6.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8, beta = 0.010000, Train MSE: 0.415161, Train CE:1.299456, Train KL:2.430321, Val MSE:0.396248, Val CE:1.206525, Train ACC:0.565355, Val ACC:0.579462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 8/8 [00:01<00:00,  6.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9, beta = 0.010000, Train MSE: 0.379557, Train CE:1.143850, Train KL:2.742451, Val MSE:0.368619, Val CE:1.071381, Train ACC:0.691323, Val ACC:0.693426\n",
      "Training time: 0.2356 mins\n",
      "Successfully load and save the model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model, pre_encoder, pre_decoder = tabsyn.train_vae(model, pre_encoder, pre_decoder, \n",
    "                                                   optimizer, scheduler, **raw_config[\"loss_params\"], \n",
    "                                                   num_epochs = raw_config[\"train\"][\"vae\"][\"num_epochs\"], \n",
    "                                                   model_save_path = f\"{MODEL_PATH}/{DATA_NAME}/vae/model.pt\",\n",
    "                                                   encoder_save_path = f\"{MODEL_PATH}/{DATA_NAME}/vae/encoder.pt\", \n",
    "                                                   decoder_save_path = f\"{MODEL_PATH}/{DATA_NAME}/vae/decoder.pt\",  device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully save pretrained embeddings in disk!\n"
     ]
    }
   ],
   "source": [
    "# embed all inputs in the latent space\n",
    "tabsyn.save_vae_embeddings(pre_encoder, \n",
    "                           X_train_num, X_train_cat,\n",
    "                           vae_ckpt_dir = f\"{MODEL_PATH}/{DATA_NAME}/vae\", \n",
    "                           device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Diffusion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load latent space embeddings\n",
    "train_z, _ = tabsyn.load_vae_embeddings(vae_ckpt_dir = f\"{MODEL_PATH}/{DATA_NAME}/vae\")\n",
    "\n",
    "# normalize embeddings\n",
    "mean, std = train_z.mean(0), train_z.std(0)\n",
    "train_z = (train_z - mean) / 2\n",
    "train_data = train_z\n",
    "\n",
    "# create data loader\n",
    "train_loader = DataLoader(\n",
    "    train_data,\n",
    "    batch_size = raw_config[\"train\"][\"diffusion\"][\"batch_size\"],\n",
    "    shuffle = True,\n",
    "    num_workers = 4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPDiffusion(\n",
      "  (proj): Linear(in_features=60, out_features=1024, bias=True)\n",
      "  (mlp): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=2048, bias=True)\n",
      "    (1): SiLU()\n",
      "    (2): Linear(in_features=2048, out_features=2048, bias=True)\n",
      "    (3): SiLU()\n",
      "    (4): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "    (5): SiLU()\n",
      "    (6): Linear(in_features=1024, out_features=60, bias=True)\n",
      "  )\n",
      "  (map_noise): PositionalEmbedding()\n",
      "  (time_embed): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    (1): SiLU()\n",
      "    (2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "  )\n",
      ")\n",
      "the number of parameters 10616892\n"
     ]
    }
   ],
   "source": [
    "# load diffusion model\n",
    "model = tabsyn.get_diffusion_model(in_dim = train_z.shape[1], hid_dim = train_z.shape[1], device = device)\n",
    "\n",
    "# load optimizer and scheduler\n",
    "optimizer, scheduler = tabsyn.load_optim(model, **raw_config[\"train\"][\"diffusion\"][\"optim\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 8/8 [00:00<00:00,  8.07it/s, Loss=0.86] \n",
      "Epoch 2/10: 100%|██████████| 8/8 [00:00<00:00,  8.41it/s, Loss=0.772]\n",
      "Epoch 3/10: 100%|██████████| 8/8 [00:00<00:00,  8.34it/s, Loss=0.732]\n",
      "Epoch 4/10: 100%|██████████| 8/8 [00:00<00:00,  8.18it/s, Loss=0.688]\n",
      "Epoch 5/10: 100%|██████████| 8/8 [00:00<00:00,  8.26it/s, Loss=0.657]\n",
      "Epoch 6/10: 100%|██████████| 8/8 [00:00<00:00,  8.18it/s, Loss=0.594]\n",
      "Epoch 7/10: 100%|██████████| 8/8 [00:00<00:00,  8.22it/s, Loss=0.593]\n",
      "Epoch 8/10: 100%|██████████| 8/8 [00:00<00:00,  8.69it/s, Loss=0.68] \n",
      "Epoch 9/10: 100%|██████████| 8/8 [00:00<00:00,  8.23it/s, Loss=0.524]\n",
      "Epoch 10/10: 100%|██████████| 8/8 [00:01<00:00,  7.71it/s, Loss=0.469]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  10.753646850585938\n"
     ]
    }
   ],
   "source": [
    "# train diffusion model\n",
    "tabsyn.train_diffusion(model, train_loader, optimizer, scheduler, \n",
    "                       num_epochs = raw_config[\"train\"][\"diffusion\"][\"num_epochs\"],\n",
    "                       ckpt_path = f\"{MODEL_PATH}/{DATA_NAME}\",\n",
    "                       device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # model_name= \"model_1000.pt\"\n",
    "# model_name= \"model.pt\"\n",
    "\n",
    "# model, pre_encoder, pre_decoder = tabsyn.load_model(\n",
    "#     model, pre_encoder, pre_decoder,\n",
    "#     ckpt_dir = f\"{MODEL_PATH}/{DATA_NAME}\",\n",
    "#     model_name = model_name,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_path /projects/aieng/diffusion_bootcamp/data/tabular_copy/processed_data/adult\n",
      "No NaNs in numerical features, skipping\n"
     ]
    }
   ],
   "source": [
    "steps = raw_config[\"sample\"][\"steps\"]\n",
    "save_path = f\"{SYNTH_DATA_DIR}/{DATA_NAME}/tabsyn.csv\"\n",
    "ckpt_path = f\"{MODEL_PATH}/{DATA_NAME}\"\n",
    "\n",
    "train_z, token_dim = tabsyn.load_vae_embeddings(vae_ckpt_dir = f\"{MODEL_PATH}/{DATA_NAME}/vae\")\n",
    "\n",
    "with open(f\"{PROCESSED_DATA_DIR}/{DATA_NAME}/info.json\", \"r\") as file:\n",
    "    data_info = json.load(file)\n",
    "data_info['token_dim'] = token_dim\n",
    "task_type = data_info['task_type']\n",
    "\n",
    "_, _, categories, d_numerical, num_inverse, cat_inverse = preprocess(f\"{PROCESSED_DATA_DIR}/{DATA_NAME}\", task_type = task_type, inverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, pre_decoder = tabsyn.load_model(\n",
    "    in_dim = train_z.shape[1], hid_dim = train_z.shape[1],\n",
    "    ckpt_dir = f\"{MODEL_PATH}/{DATA_NAME}\",\n",
    "    device = device,\n",
    "    d_numerical = d_numerical, \n",
    "    categories = categories,\n",
    "    **raw_config[\"model_params\"][\"vae\"],  \n",
    ")\n",
    "\n",
    "data_info['pre_decoder'] = pre_decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32561, 9)\n",
      "Time: 15.872112512588501\n",
      "Saving sampled data to /projects/aieng/diffusion_bootcamp/data/tabular_copy/synthetic_data/adult/tabsyn.csv\n"
     ]
    }
   ],
   "source": [
    "tabsyn.sample(model, train_z, data_info, num_inverse, cat_inverse, save_path, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally here, we review the synthesized data. In the following `evaluate_synthetic_data.ipynb` notebook, we will evaluate this synthesized data with respect to various metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education.num</th>\n",
       "      <th>marital.status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>native.country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34.0</td>\n",
       "      <td>?</td>\n",
       "      <td>177972.88</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Tech-support</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>160227.14</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46.0</td>\n",
       "      <td>Federal-gov</td>\n",
       "      <td>195279.36</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>11.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55.0</td>\n",
       "      <td>?</td>\n",
       "      <td>155793.06</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>11.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>169466.77</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>11.0</td>\n",
       "      <td>Married-spouse-absent</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age     workclass     fnlwgt      education  education.num  \\\n",
       "0  34.0             ?  177972.88        HS-grad           12.0   \n",
       "1  63.0       Private  160227.14        HS-grad            9.0   \n",
       "2  46.0   Federal-gov  195279.36        HS-grad           11.0   \n",
       "3  55.0             ?  155793.06      Bachelors           11.0   \n",
       "4  26.0       Private  169466.77   Some-college           11.0   \n",
       "\n",
       "           marital.status        occupation    relationship    race    sex  \\\n",
       "0           Never-married      Tech-support   Not-in-family   White   Male   \n",
       "1      Married-civ-spouse      Craft-repair         Husband   White   Male   \n",
       "2      Married-civ-spouse   Exec-managerial   Not-in-family   White   Male   \n",
       "3      Married-civ-spouse    Prof-specialty         Husband   White   Male   \n",
       "4   Married-spouse-absent   Exec-managerial   Not-in-family   White   Male   \n",
       "\n",
       "   capital.gain  capital.loss  hours.per.week  native.country  income  \n",
       "0           0.0           0.0            40.0   United-States   <=50K  \n",
       "1           0.0           0.0            40.0   United-States   <=50K  \n",
       "2           0.0           0.0            40.0   United-States   <=50K  \n",
       "3           0.0           0.0            40.0   United-States   <=50K  \n",
       "4           0.0           0.0            40.0   United-States   <=50K  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f\"{SYNTH_DATA_DIR}/{DATA_NAME}/tabsyn.csv\")\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zhang, Hengrui, et al.** \"Mixed-type tabular data synthesis with score-based diffusion in latent space.\" *International Conference on Learning Representations (ICLR)* (2023).\n",
    "\n",
    "**GitHub Repository:** [Amazon Science - Tabsyn](https://github.com/amazon-science/tabsyn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffusion_boot_yasaman",
   "language": "python",
   "name": "diffusion_boot_yasaman"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
