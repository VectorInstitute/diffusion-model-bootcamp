{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "comprehensive-logging",
   "metadata": {},
   "source": [
    "<center>\n",
    "  \n",
    "# TABDDPM: Modelling Tabular Data with Diffusion Models\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1d7a55",
   "metadata": {},
   "source": [
    "Directly applying diffusion models to general tabular problems can be challenging because data points are typically represented by vectors of heterogeneous features. The inherent heterogeneity of tabular data complicates accurate modeling, as individual features can vary widely in nature; some may be continuous, while others are discrete. In this notebook, we explore **TabDDPM** â€” a diffusion model that can be universally applied to tabular datasets and effectively handles both categorical and numerical features.\n",
    "\n",
    "Our primary focus in this work is synthetic data generation, which is in high demand for many tabular tasks. Firstly, tabular datasets are often limited in size, unlike vision or NLP problems where large amounts of additional data are readily available online. Secondly, properly generated synthetic datasets do not contain actual user data, thus avoiding GDPR-like regulations and allowing for public sharing without compromising anonymity.\n",
    "\n",
    "In the following sections, we will delve deeper into the implementation of this method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7a5190",
   "metadata": {},
   "source": [
    "# Imports and Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16c75e8",
   "metadata": {},
   "source": [
    "In this section, we import all necessary libraries and modules required for setting up the environment. This includes basic libraries for such numpy and pandas. We also import essential modules for data loading, model creation, and dataset downloading and processing dataset. We also specify list of possible datasets and their download URL in `NAME_URL_DICT_UCI` where you can use each of these datasets for the rest of this notebook. Furthermore based on `DATA_DIR` we specify path to raw and processed data in `RAW_DATA_DIR` and `PROCESSED_DATA_DIR` to further download the data and process it in a desired format.  Here we will focus on `\"adult\"` dataset thus we will specify it in `DATA_NAME`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cooperative-tanzania",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import src\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scripts.download_dataset import download_from_uci\n",
    "from scripts.process_dataset import process_data\n",
    "\n",
    "from src.data import make_dataset\n",
    "from src.baselines.tabddpm.pipeline import TabDDPM\n",
    "\n",
    "\n",
    "NAME_URL_DICT_UCI = {\n",
    "    \"adult\": \"https://archive.ics.uci.edu/static/public/2/adult.zip\",\n",
    "    \"default\": \"https://archive.ics.uci.edu/static/public/350/default+of+credit+card+clients.zip\",\n",
    "    \"magic\": \"https://archive.ics.uci.edu/static/public/159/magic+gamma+telescope.zip\",\n",
    "    \"shoppers\": \"https://archive.ics.uci.edu/static/public/468/online+shoppers+purchasing+intention+dataset.zip\",\n",
    "    \"beijing\": \"https://archive.ics.uci.edu/static/public/381/beijing+pm2+5+data.zip\",\n",
    "    \"news\": \"https://archive.ics.uci.edu/static/public/332/online+news+popularity.zip\",\n",
    "}\n",
    "\n",
    "DATA_DIR = \"/projects/aieng/diffusion_bootcamp/data/tabular\"\n",
    "RAW_DATA_DIR = f\"{DATA_DIR}/raw_data\"\n",
    "PROCESSED_DATA_DIR = f\"{DATA_DIR}/processed_data\"\n",
    "SYNTH_DATA_DIR = f\"{DATA_DIR}/synthetic_data\"\n",
    "DATA_NAME = \"adult\"\n",
    "\n",
    "MODEL_PATH = f\"/projects/aieng/diffusion_bootcamp/models/tabular/tabddpm\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc51ac5c",
   "metadata": {},
   "source": [
    "# Adult Dataset\n",
    "\n",
    "In this section, we will download the Adult dataset from the UCI repository and load it into a pandas DataFrame. The Adult dataset contains demographic information about individuals, such as age, education, and occupation, and is commonly used for classification tasks. We will use this dataset to demonstrate the TabDDPM method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ready-utility",
   "metadata": {},
   "source": [
    "## Download Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3100d23",
   "metadata": {},
   "source": [
    "We can download the required adult dataset to the specified directory in `RAW_DATA_DIR` using the download_from_uci function. This function takes the dataset name, the download path, and the URL of the data, and retrieves it from the UCI repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "adolescent-korea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start processing dataset adult from UCI.\n",
      "Aready downloaded.\n"
     ]
    }
   ],
   "source": [
    "download_from_uci(DATA_NAME, RAW_DATA_DIR, NAME_URL_DICT_UCI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fitting-blend",
   "metadata": {},
   "source": [
    "## Process Data\n",
    "\n",
    "Now that we have downloaded the dataset, we need to process it into the desired CSV format using the `process_data` function. To do this, we provide the dataset name, the directory containing the information required for preprocessing, and the original data directory. The `INFO_DIR` contains a JSON file for each dataset, specifying the following:\n",
    "\n",
    "1. task_type: This must be specified and can be binclass (binary classification) or regression, depending on the type of task for each dataset. For the adult dataset, the task type is binclass.\n",
    "2. column_names: This is optional and contains the names of each column.\n",
    "3. num_col_idx: This is necessary to specify the columns with numerical values.\n",
    "4. cat_col_idx: This is necessary to specify the columns with categorical values.\n",
    "5. target_col_idx: This is necessary to specify the column containing the target value for the regression or classification task.\n",
    "6. file_type: This should be set to \"csv\" by default, as we want to preprocess the files as CSV.\n",
    "7. data_path: Optional\n",
    "8. test_path: Optional\n",
    "9. column_info: Optional\n",
    "10. train_num: Optional\n",
    "11. test_num: Optional\n",
    "\n",
    "The `process_data` function divides the raw data into training and test splits, saving them in `PROCESSED_DATA_DIR`. It also saves the processed information of the data as a JSON file in the same directory. Finally, it prints out general information about the training and test data after preprocessing, including:\n",
    "\n",
    "1. Size of the training, validation, and test tables\n",
    "2. Size of the numerical values in the training table\n",
    "3. Size of the categorical values in the training table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "simplified-ending",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adult (32561, 15) (16281, 15) (32561, 15)\n",
      "Numerical (32561, 6)\n",
      "Categorical (32561, 8)\n",
      "Processing and Saving adult Successfully!\n",
      "adult\n",
      "Total 48842\n",
      "Train 32561\n",
      "Test 16281\n",
      "Num 6\n",
      "Cat 9\n"
     ]
    }
   ],
   "source": [
    "INFO_DIR = \"data_info\"\n",
    "process_data(DATA_NAME, INFO_DIR, DATA_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "another-cologne",
   "metadata": {},
   "source": [
    "## Review Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad79ab5",
   "metadata": {},
   "source": [
    "Following preprocessing, here we will review the train dataset.\n",
    "\n",
    "Adult dataset consist of 15 columns in total where 6 columns are numerical and 9 columns are categorical. The target column is `income` which is a binary classification task. The dataset contains 32561 rows in total. You can see 20 first rows of the dataset below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "rapid-booth",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education.num</th>\n",
       "      <th>marital.status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>native.country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39.0</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516.0</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50.0</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311.0</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646.0</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721.0</td>\n",
       "      <td>11th</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409.0</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>37.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>284582.0</td>\n",
       "      <td>Masters</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>49.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>160187.0</td>\n",
       "      <td>9th</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Married-spouse-absent</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>Jamaica</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>52.0</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>209642.0</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>31.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>45781.0</td>\n",
       "      <td>Masters</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>14084.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>42.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>159449.0</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>5178.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>37.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>280464.0</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>30.0</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>141297.0</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>India</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>23.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>122272.0</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>32.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>205019.0</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>40.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>121772.0</td>\n",
       "      <td>Assoc-voc</td>\n",
       "      <td>11.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>?</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>34.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>245487.0</td>\n",
       "      <td>7th-8th</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Transport-moving</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Amer-Indian-Eskimo</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>25.0</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>176756.0</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>32.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>186824.0</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>38.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>28887.0</td>\n",
       "      <td>11th</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>43.0</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>292175.0</td>\n",
       "      <td>Masters</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age          workclass    fnlwgt      education  education.num  \\\n",
       "0   39.0          State-gov   77516.0      Bachelors           13.0   \n",
       "1   50.0   Self-emp-not-inc   83311.0      Bachelors           13.0   \n",
       "2   38.0            Private  215646.0        HS-grad            9.0   \n",
       "3   53.0            Private  234721.0           11th            7.0   \n",
       "4   28.0            Private  338409.0      Bachelors           13.0   \n",
       "5   37.0            Private  284582.0        Masters           14.0   \n",
       "6   49.0            Private  160187.0            9th            5.0   \n",
       "7   52.0   Self-emp-not-inc  209642.0        HS-grad            9.0   \n",
       "8   31.0            Private   45781.0        Masters           14.0   \n",
       "9   42.0            Private  159449.0      Bachelors           13.0   \n",
       "10  37.0            Private  280464.0   Some-college           10.0   \n",
       "11  30.0          State-gov  141297.0      Bachelors           13.0   \n",
       "12  23.0            Private  122272.0      Bachelors           13.0   \n",
       "13  32.0            Private  205019.0     Assoc-acdm           12.0   \n",
       "14  40.0            Private  121772.0      Assoc-voc           11.0   \n",
       "15  34.0            Private  245487.0        7th-8th            4.0   \n",
       "16  25.0   Self-emp-not-inc  176756.0        HS-grad            9.0   \n",
       "17  32.0            Private  186824.0        HS-grad            9.0   \n",
       "18  38.0            Private   28887.0           11th            7.0   \n",
       "19  43.0   Self-emp-not-inc  292175.0        Masters           14.0   \n",
       "\n",
       "            marital.status          occupation    relationship  \\\n",
       "0            Never-married        Adm-clerical   Not-in-family   \n",
       "1       Married-civ-spouse     Exec-managerial         Husband   \n",
       "2                 Divorced   Handlers-cleaners   Not-in-family   \n",
       "3       Married-civ-spouse   Handlers-cleaners         Husband   \n",
       "4       Married-civ-spouse      Prof-specialty            Wife   \n",
       "5       Married-civ-spouse     Exec-managerial            Wife   \n",
       "6    Married-spouse-absent       Other-service   Not-in-family   \n",
       "7       Married-civ-spouse     Exec-managerial         Husband   \n",
       "8            Never-married      Prof-specialty   Not-in-family   \n",
       "9       Married-civ-spouse     Exec-managerial         Husband   \n",
       "10      Married-civ-spouse     Exec-managerial         Husband   \n",
       "11      Married-civ-spouse      Prof-specialty         Husband   \n",
       "12           Never-married        Adm-clerical       Own-child   \n",
       "13           Never-married               Sales   Not-in-family   \n",
       "14      Married-civ-spouse        Craft-repair         Husband   \n",
       "15      Married-civ-spouse    Transport-moving         Husband   \n",
       "16           Never-married     Farming-fishing       Own-child   \n",
       "17           Never-married   Machine-op-inspct       Unmarried   \n",
       "18      Married-civ-spouse               Sales         Husband   \n",
       "19                Divorced     Exec-managerial       Unmarried   \n",
       "\n",
       "                   race      sex  capital.gain  capital.loss  hours.per.week  \\\n",
       "0                 White     Male        2174.0           0.0            40.0   \n",
       "1                 White     Male           0.0           0.0            13.0   \n",
       "2                 White     Male           0.0           0.0            40.0   \n",
       "3                 Black     Male           0.0           0.0            40.0   \n",
       "4                 Black   Female           0.0           0.0            40.0   \n",
       "5                 White   Female           0.0           0.0            40.0   \n",
       "6                 Black   Female           0.0           0.0            16.0   \n",
       "7                 White     Male           0.0           0.0            45.0   \n",
       "8                 White   Female       14084.0           0.0            50.0   \n",
       "9                 White     Male        5178.0           0.0            40.0   \n",
       "10                Black     Male           0.0           0.0            80.0   \n",
       "11   Asian-Pac-Islander     Male           0.0           0.0            40.0   \n",
       "12                White   Female           0.0           0.0            30.0   \n",
       "13                Black     Male           0.0           0.0            50.0   \n",
       "14   Asian-Pac-Islander     Male           0.0           0.0            40.0   \n",
       "15   Amer-Indian-Eskimo     Male           0.0           0.0            45.0   \n",
       "16                White     Male           0.0           0.0            35.0   \n",
       "17                White     Male           0.0           0.0            40.0   \n",
       "18                White     Male           0.0           0.0            50.0   \n",
       "19                White   Female           0.0           0.0            45.0   \n",
       "\n",
       "    native.country  income  \n",
       "0    United-States   <=50K  \n",
       "1    United-States   <=50K  \n",
       "2    United-States   <=50K  \n",
       "3    United-States   <=50K  \n",
       "4             Cuba   <=50K  \n",
       "5    United-States   <=50K  \n",
       "6          Jamaica   <=50K  \n",
       "7    United-States    >50K  \n",
       "8    United-States    >50K  \n",
       "9    United-States    >50K  \n",
       "10   United-States    >50K  \n",
       "11           India    >50K  \n",
       "12   United-States   <=50K  \n",
       "13   United-States   <=50K  \n",
       "14               ?    >50K  \n",
       "15          Mexico   <=50K  \n",
       "16   United-States   <=50K  \n",
       "17   United-States   <=50K  \n",
       "18   United-States   <=50K  \n",
       "19   United-States    >50K  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f\"{PROCESSED_DATA_DIR}/{DATA_NAME}/train.csv\")\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7ee997",
   "metadata": {},
   "source": [
    "Also this dataset contains missing values which are represented as `?` in the dataset. We will replace these missing values with the most frequent value in the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "brown-curtis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ? exists in the DataFrame.\n"
     ]
    }
   ],
   "source": [
    "value = \" ?\"\n",
    "if value in df.values:\n",
    "    print(f\"{value} exists in the DataFrame.\")\n",
    "else:\n",
    "    print(f\"{value} does not exist in the DataFrame.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "adjusted-respect",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'adult', 'task_type': 'binclass', 'header': None, 'column_names': ['age', 'workclass', 'fnlwgt', 'education', 'education.num', 'marital.status', 'occupation', 'relationship', 'race', 'sex', 'capital.gain', 'capital.loss', 'hours.per.week', 'native.country', 'income'], 'num_col_idx': [0, 2, 4, 10, 11, 12], 'cat_col_idx': [1, 3, 5, 6, 7, 8, 9, 13], 'target_col_idx': [14], 'file_type': 'csv', 'data_path': '/projects/aieng/diffusion_bootcamp/data/tabular/raw_data/adult/adult.data', 'test_path': '/projects/aieng/diffusion_bootcamp/data/tabular/raw_data/adult/adult.test', 'column_info': {'0': {}, 'type': 'categorical', 'max': 99.0, 'min': 1.0, '2': {}, '4': {}, '10': {}, '11': {}, '12': {}, '1': {}, 'categorizes': [' <=50K', ' >50K'], '3': {}, '5': {}, '6': {}, '7': {}, '8': {}, '9': {}, '13': {}, '14': {}}, 'train_num': 32561, 'test_num': 16281, 'idx_mapping': {'0': 0, '1': 6, '2': 1, '3': 7, '4': 2, '5': 8, '6': 9, '7': 10, '8': 11, '9': 12, '10': 3, '11': 4, '12': 5, '13': 13, '14': 14}, 'inverse_idx_mapping': {'0': 0, '6': 1, '1': 2, '7': 3, '2': 4, '8': 5, '9': 6, '10': 7, '11': 8, '12': 9, '3': 10, '4': 11, '5': 12, '13': 13, '14': 14}, 'idx_name_mapping': {'0': 'age', '1': 'workclass', '2': 'fnlwgt', '3': 'education', '4': 'education.num', '5': 'marital.status', '6': 'occupation', '7': 'relationship', '8': 'race', '9': 'sex', '10': 'capital.gain', '11': 'capital.loss', '12': 'hours.per.week', '13': 'native.country', '14': 'income'}, 'metadata': {'columns': {'0': {'sdtype': 'numerical', 'computer_representation': 'Float'}, '2': {'sdtype': 'numerical', 'computer_representation': 'Float'}, '4': {'sdtype': 'numerical', 'computer_representation': 'Float'}, '10': {'sdtype': 'numerical', 'computer_representation': 'Float'}, '11': {'sdtype': 'numerical', 'computer_representation': 'Float'}, '12': {'sdtype': 'numerical', 'computer_representation': 'Float'}, '1': {'sdtype': 'categorical'}, '3': {'sdtype': 'categorical'}, '5': {'sdtype': 'categorical'}, '6': {'sdtype': 'categorical'}, '7': {'sdtype': 'categorical'}, '8': {'sdtype': 'categorical'}, '9': {'sdtype': 'categorical'}, '13': {'sdtype': 'categorical'}, '14': {'sdtype': 'categorical'}}}}\n"
     ]
    }
   ],
   "source": [
    "# Open the JSON file and read its contents\n",
    "with open(f\"{PROCESSED_DATA_DIR}/{DATA_NAME}/info.json\", \"r\") as file:\n",
    "    data_info = json.load(file)\n",
    "\n",
    "# Display the JSON data\n",
    "print(data_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moderate-factory",
   "metadata": {},
   "source": [
    "# TabDDPM Algorithem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5daaffdc",
   "metadata": {},
   "source": [
    "In this section, we will describe the design of TabDDPM as well as its main hyperparameters loaded through config, which affect the modelâ€™s effectiveness. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b425e7",
   "metadata": {},
   "source": [
    "**TabDDPM:** uses the multinomial diffusion to model the categorical and binary features, and the Gaussian diffusion to model the numerical ones. The model is trained using the diffusion process, which is a continuous-time Markov chain that models the data distribution. In more detail, for a tabular data sample that consists of N numerical featuresand C categorical features with Ki categories each, TabDDPM takes one-hot encoded versions of categorical features as an input, and normalized numerical features. The figure below illustrates the diffusion process for classification problems; t, y and l denote a diffusion timestep, a class label, and logits, respectively.\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"figures/tabddpm.png\" width=\"1000\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37161c0",
   "metadata": {},
   "source": [
    "**Diffusion models:**  are likelihood-based generative models that handle the data through forward and reverse Markov processes. The forward process gradually adds noise to an initial sample x0 from the data distribution q(x0) sampling noise from the predefined distributions q(xt|xtâˆ’1) with variances {Î²1, ..., Î²T}.\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"figures/forward.png\" width=\"300\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e6bfff",
   "metadata": {},
   "source": [
    "The reverse diffusion proces gradually denoises a latent variable xTâˆ¼q(xT) and allows generating new data samples from q(x0). Distributions p(xtâˆ’1|xt) are usually unknown and approximated by a neural network with parameters Î¸.\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"figures/backward.png\" width=\"280\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1c2058",
   "metadata": {},
   "source": [
    "**Gaussian diffusion models:** operate in continuous spaces where forward and reverse processes are characterized by Gaussian distributions:\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"figures/gaussian.png\" width=\"440\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad099f5",
   "metadata": {},
   "source": [
    "While in general Î¸ parameters are learned from the data by optimizing a variational lower bound, in practice for Gaussian modeling, this objective can be simplified to the sum of mean-squared errors between ÎµÎ¸(xt ,t) and Îµ over all timesteps t as follows:\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"figures/gaussian_loss.png\" width=\"330\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24a46d1",
   "metadata": {},
   "source": [
    "**Multinomial diffusion models:** are designed to generate categorical data where samples are a one-hot encoded categorical variable with K values. The multinomial forward diffusion process defines q(xt|xtâˆ’1) as a categorical distribution that corrupts the data by uniform noise over K classes: \n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"figures/multinomial.png\" width=\"440\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d537779d",
   "metadata": {},
   "source": [
    "The reverse distribution pÎ¸(xtâˆ’1|xt) is parameterized as q(xtâˆ’1|xt,xË†0(xt,t)), where xË†0 is predicted by a neural network. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f362ca1",
   "metadata": {},
   "source": [
    "## Load Config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7213754",
   "metadata": {},
   "source": [
    "In this section, we will load the configuration file that contains the hyperparameters for the TabDDPM model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a5701a",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = f\"../code/src/baselines/tabddpm/configs/{DATA_NAME}.toml\"\n",
    "## Tabddpm is trained unconditional in this repo but conditional in main paper\n",
    "raw_config = src.load_config(config_path)\n",
    "\n",
    "print(raw_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871a2bc8",
   "metadata": {},
   "source": [
    "The configuration file is a TOML file that contains the following hyperparameters:\n",
    "\n",
    "1. **model_type:**  specifies the type of backbone model to be used for learning the denoising process. For Adult dataset, this should be set to \"mlp\". The reverse diffusion step in TabDDPM is modelled by a multi-layer neural network that has an output of the same dimensionality as x0, where the first N coordinates are the predictions of Îµ for the Gaussian diffusion and the rest are the predictions of x_ohe for the multinomial diffusions. This model takes as input the corrupted data xt and the timestep t, and outputs the denoised data xtâˆ’1 as follows:\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"figures/architecture.png\" width=\"440\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1b8823",
   "metadata": {},
   "source": [
    "2. **model_params:** contains the hyperparameters for the backbone model. For the Adult dataset, we use an MLP model with the following hyperparameters:\n",
    "    - is_y_cond: Whether the model is trained to be conditioned on the target value or not. By default, this should be set to True.\n",
    "    - d_layers: The dimension of layers in the MLP model.\n",
    "    - dropout: The dropout rate.\n",
    "\n",
    "\n",
    "    \n",
    "3. **task_type:** specifice the task type that we will use to conidition our training to and can be binclass (binary classification) or regression, depending on each dataset. For the Adult dataset, the task type is binclass. For classification datasets, we use a class- conditional model, i.e. pÎ¸(xtâˆ’1|xt, y) is learned. For regression datasets, we consider a target value as an additional numerical feature, and the joint distribution is learned.\n",
    "\n",
    "4. **diffusion_params:** contains number of total diffusion steps, the diffusion step size, and type of loss used to minimize the predicited noise in Gaussian diffusion. \n",
    "\n",
    "5. **train.main:** contains the basic hyperparameters for training the model such number of epochs (steps), the batch size (batch_size), the learning rate(lr), and the rate of weight decay (weight_decay).\n",
    "\n",
    "6. **train.T:** contains the defined transformations on train data such as normalization, standardization, and one-hot encoding. \n",
    "    - For preprocessing numerical features, we use the gaussian quantile transformation and replace the Nan values with mean of each row. \n",
    "    - For categorical features, we use the one-hot encoding method. Each categorical feature is handled by a separate forward diffusion process, i.e., the noise components for all features are sampled independently. \n",
    "\n",
    "7. **sample:** contains the hyperparameters for sampling the data from the trained model. It includes the number of samples to generate, the batch size of sampling, and the seed used for random noise initialization.\n",
    "\n",
    "8. **eval.T:** contains the defined transformations on evaluation data such as normalization, standardization, and one-hot encoding. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "failing-quality",
   "metadata": {},
   "source": [
    "## Make Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b6854c",
   "metadata": {},
   "source": [
    "Now that we have processed the data, we can create a dataset object. First we instantiate transformations needed for the dataset, such as normalization, standardization, and one-hot encoding in `T`. Next using make_dataset function we create a dataset object that contains the training and test data, as well as the column names, numerical column indices, and categorical column indices. This function takes the directory containing the processed data, the transformation and task type as input. Also it takes a boolean argument `change_val` that if it set true it will change the validation data to a split of train data rather than test data.\n",
    "It returns a dataset object that contains the training and test data, as well as the column names, numerical column indices, and categorical column indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "second-romance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_path /projects/aieng/diffusion_bootcamp/data/tabular/processed_data/adult\n",
      "No NaNs in numerical features, skipping\n"
     ]
    }
   ],
   "source": [
    "T = src.Transformations(**raw_config[\"train\"][\"T\"])\n",
    "\n",
    "dataset = make_dataset(\n",
    "    f\"{PROCESSED_DATA_DIR}/{DATA_NAME}\",\n",
    "    T,\n",
    "    task_type=raw_config[\"task_type\"],\n",
    "    change_val=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "billion-convention",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset num shape:  (32561, 6)\n",
      "test dataset num shape:  (16281, 6)\n",
      "train dataset cat shape:  (32561, 9)\n",
      "test dataset cat shape:  (16281, 9)\n",
      "{'policy': 'default'}\n",
      "binclass\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(\"train dataset num shape: \", dataset.X_num[\"train\"].shape)\n",
    "print(\"test dataset num shape: \", dataset.X_num[\"test\"].shape)\n",
    "\n",
    "print(\"train dataset cat shape: \", dataset.X_cat[\"train\"].shape)\n",
    "print(\"test dataset cat shape: \", dataset.X_cat[\"test\"].shape)\n",
    "\n",
    "print(dataset.y_info)\n",
    "print(dataset.task_type)\n",
    "print(dataset.n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2b294c",
   "metadata": {},
   "source": [
    "## Instantiate Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984a84c6",
   "metadata": {},
   "source": [
    "Next, we instantiate the TabDDPM model. To do so first we need to apply some modifactions to loaded configs based on the dataset. We will set the number of numerical and size of one-hot coded categorical features based on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "allied-sunday",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2  9 16  7 15  6  5  2 42]\n",
      "[ 2  9 16  7 15  6  5  2 42]\n",
      "110\n"
     ]
    }
   ],
   "source": [
    "dim_categorical_features = np.array(dataset.get_category_sizes(\"train\"))\n",
    "print(dim_categorical_features)\n",
    "if len(dim_categorical_features) == 0 or raw_config[\"train\"][\"T\"][\"cat_encoding\"] == \"one-hot\":\n",
    "    dim_categorical_features = np.array([0])\n",
    "\n",
    "num_numerical_features = (\n",
    "    dataset.X_num[\"train\"].shape[1] if dataset.X_num is not None else 0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59532a94",
   "metadata": {},
   "source": [
    "We will also set the input size of the model as sum of size of categorical plus length of numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2fb00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_input = np.sum(dim_categorical_features) + num_numerical_features\n",
    "raw_config[\"model_params\"][\"d_in\"] = dim_input\n",
    "print(dim_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a14719",
   "metadata": {},
   "source": [
    "Also we set device to be \"cuda\" if available otherwise we will use \"cpu\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f47437f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3661314c",
   "metadata": {},
   "source": [
    "Finally, we will instantiate the model using the `TabDDPM` class. TabDDPM class takes the following arguments:\n",
    "\n",
    "1. dataset: The dataset object containing the training and test data, as well as the column names, numerical column indices, and categorical column indices.\n",
    "2. num_numerical_features: The number of numerical features in the dataset.\n",
    "3. dim_categorical_features: The list of size of the one-hot encoded categorical features.\n",
    "4. model_type: The type of backbone model to be used for learning the denoising process.\n",
    "5. model_params: The hyperparameters for the backbone model.\n",
    "6. diffusion_params: The hyperparameters for the diffusion process.\n",
    "7. device: The device to use for training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "developed-gross",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_classes': 2, 'is_y_cond': False, 'rtdl_params': {'d_layers': [1024, 2048, 2048, 1024], 'dropout': 0.0}, 'd_in': 110}\n",
      "mlp\n",
      "the number of parameters 11768942\n"
     ]
    }
   ],
   "source": [
    "tabddpm = TabDDPM(\n",
    "    dataset=dataset,\n",
    "    num_numerical_features=num_numerical_features,\n",
    "    num_classes=dim_categorical_features,\n",
    "    model_type=raw_config[\"model_type\"],\n",
    "    model_params=raw_config[\"model_params\"],\n",
    "    device=device,\n",
    "    **raw_config[\"diffusion_params\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38efa0e",
   "metadata": {},
   "source": [
    "TabDDPM class first instantiates the backbone model, which is a multi-layer neural network that models the reverse diffusion process using `get_model` function. It then passes this model to `GaussianMultinomialDiffusion` class to initializes the diffusion process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "federal-boost",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f204dce9",
   "metadata": {},
   "source": [
    "Now that we have instantiated the model, we can train it using the `train` function. This function takes the training arguments from the config file and path to save the trained model. It trains the model on the training data using the `Trainer` class. It returns the trained model and the training loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "russian-jimmy",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps:  100000\n",
      "Step 1/100000 MLoss: 2.1247 GLoss: 1.2061 Sum: 3.3308\n",
      "Time:  0.20956921577453613\n",
      "Step 2/100000 MLoss: 46.4899 GLoss: 80031.0 Sum: 80077.4899\n",
      "Time:  0.11751985549926758\n",
      "Step 3/100000 MLoss: 1.6049 GLoss: 2.4237 Sum: 4.0286\n",
      "Time:  0.09335041046142578\n",
      "Step 4/100000 MLoss: 1.6683 GLoss: 1.6124 Sum: 3.2807\n",
      "Time:  0.15784645080566406\n",
      "Step 5/100000 MLoss: 1.7956 GLoss: 1.0445 Sum: 2.8401\n",
      "Time:  0.13161206245422363\n",
      "Step 6/100000 MLoss: 1.3912 GLoss: 1.0906 Sum: 2.4818\n",
      "Time:  0.1342473030090332\n",
      "Step 7/100000 MLoss: 1.7725 GLoss: 1.3167 Sum: 3.0892\n",
      "Time:  0.0675048828125\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtabddpm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mraw_config\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_save_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mMODEL_PATH\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mDATA_NAME\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/fs01/home/sayromlou/diffusion_model_bootcamp/reference_implementations/tabular_reference_impelementation/code/src/baselines/tabddpm/pipeline.py:98\u001b[0m, in \u001b[0;36mTabDDPM.train\u001b[0;34m(self, model_save_path, steps, lr, weight_decay, batch_size)\u001b[0m\n\u001b[1;32m     85\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m src\u001b[38;5;241m.\u001b[39mprepare_fast_dataloader(\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39mbatch_size\n\u001b[1;32m     87\u001b[0m )\n\u001b[1;32m     89\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdiffusion,\n\u001b[1;32m     91\u001b[0m     train_loader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     96\u001b[0m     device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice,\n\u001b[1;32m     97\u001b[0m )\n\u001b[0;32m---> 98\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(model_save_path):\n\u001b[1;32m    101\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(model_save_path)\n",
      "File \u001b[0;32m/fs01/home/sayromlou/diffusion_model_bootcamp/reference_implementations/tabular_reference_impelementation/code/src/baselines/tabddpm/train.py:76\u001b[0m, in \u001b[0;36mTrainer.run_loop\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     73\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     74\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_iter)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 76\u001b[0m batch_loss_multi, batch_loss_gauss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_anneal_lr(step)\n\u001b[1;32m     80\u001b[0m curr_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(x)\n",
      "File \u001b[0;32m/fs01/home/sayromlou/diffusion_model_bootcamp/reference_implementations/tabular_reference_impelementation/code/src/baselines/tabddpm/train.py:56\u001b[0m, in \u001b[0;36mTrainer._run_step\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     53\u001b[0m loss_multi, loss_gauss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdiffusion\u001b[38;5;241m.\u001b[39mmixed_loss(x)\n\u001b[1;32m     55\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_multi \u001b[38;5;241m+\u001b[39m loss_gauss\n\u001b[0;32m---> 56\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss_multi, loss_gauss\n",
      "File \u001b[0;32m/projects/aieng/diffusion_bootcamp/env/diffusion-models-bootcamp-z7DAirMd-py3.9/lib/python3.9/site-packages/torch/_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    480\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    481\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    487\u001b[0m     )\n\u001b[0;32m--> 488\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/projects/aieng/diffusion_bootcamp/env/diffusion-models-bootcamp-z7DAirMd-py3.9/lib/python3.9/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tabddpm.train(\n",
    "    **raw_config[\"train\"][\"main\"],\n",
    "    model_save_path=f\"{MODEL_PATH}/{DATA_NAME}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0624de8",
   "metadata": {},
   "source": [
    "## Load pretrained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "round-smile",
   "metadata": {},
   "source": [
    "## Sample Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6801c3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "stainless-ferry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from /projects/aieng/diffusion_bootcamp/models/tabular/tabddpm/adult/model_100000.pt\n",
      "Sample using DDIM.\n",
      "Sample timestep  999\n",
      "Sample timestep  999\n",
      "Sample timestep  999\n",
      "Sample timestep  999\n",
      "Shape torch.Size([32561, 15])\n",
      "(32561, 9)\n",
      "Sampling time: 232.29829478263855\n"
     ]
    }
   ],
   "source": [
    "model_name= \"model_100000.pt\"\n",
    "\n",
    "tabddpm.sample(\n",
    "    info_path=f\"{PROCESSED_DATA_DIR}/{DATA_NAME}/info.json\",\n",
    "    num_samples=raw_config[\"sample\"][\"num_samples\"],\n",
    "    batch_size=raw_config[\"sample\"][\"batch_size\"],\n",
    "    disbalance=raw_config[\"sample\"].get(\"disbalance\", None),\n",
    "    ckpt_path=f\"{MODEL_PATH}/{DATA_NAME}/{model_name}\",\n",
    "    sample_save_path=f\"{SYNTH_DATA_DIR}/{DATA_NAME}/tabddpm.csv\",\n",
    "    ddim=True,\n",
    "    steps=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dried-encounter",
   "metadata": {},
   "source": [
    "# Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "constitutional-price",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education.num</th>\n",
       "      <th>marital.status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>native.country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41.000000</td>\n",
       "      <td>Never-worked</td>\n",
       "      <td>98944.160</td>\n",
       "      <td>9th</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>Private</td>\n",
       "      <td>187110.600</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25.000000</td>\n",
       "      <td>Private</td>\n",
       "      <td>346842.620</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63.000000</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>230567.360</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32.000000</td>\n",
       "      <td>Private</td>\n",
       "      <td>123303.305</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>Private</td>\n",
       "      <td>201552.970</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>4386.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>53.000000</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>175929.920</td>\n",
       "      <td>Masters</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>?</td>\n",
       "      <td>100824.170</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>49.000000</td>\n",
       "      <td>?</td>\n",
       "      <td>204162.780</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Italy</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>42.000000</td>\n",
       "      <td>?</td>\n",
       "      <td>183482.920</td>\n",
       "      <td>Assoc-voc</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>21.098085</td>\n",
       "      <td>Private</td>\n",
       "      <td>219614.280</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>?</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>Private</td>\n",
       "      <td>301132.400</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>?</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>22.000000</td>\n",
       "      <td>Private</td>\n",
       "      <td>131520.840</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Separated</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1887.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Nicaragua</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>21.000000</td>\n",
       "      <td>Private</td>\n",
       "      <td>362693.120</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>?</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>51.000000</td>\n",
       "      <td>Private</td>\n",
       "      <td>300294.750</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>34.000000</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>188900.100</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>41.000000</td>\n",
       "      <td>Private</td>\n",
       "      <td>262266.530</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>64.000000</td>\n",
       "      <td>Private</td>\n",
       "      <td>116378.625</td>\n",
       "      <td>12th</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>Poland</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>43.000000</td>\n",
       "      <td>Private</td>\n",
       "      <td>52628.355</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>21.000000</td>\n",
       "      <td>?</td>\n",
       "      <td>146625.230</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>?</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          age          workclass      fnlwgt      education  education.num  \\\n",
       "0   41.000000       Never-worked   98944.160            9th            7.0   \n",
       "1   20.000000            Private  187110.600   Some-college           10.0   \n",
       "2   25.000000            Private  346842.620      Bachelors           13.0   \n",
       "3   63.000000   Self-emp-not-inc  230567.360        HS-grad            9.0   \n",
       "4   32.000000            Private  123303.305      Bachelors           13.0   \n",
       "5   27.000000            Private  201552.970   Some-college           10.0   \n",
       "6   53.000000   Self-emp-not-inc  175929.920        Masters           14.0   \n",
       "7   20.000000                  ?  100824.170        HS-grad            9.0   \n",
       "8   49.000000                  ?  204162.780        HS-grad            9.0   \n",
       "9   42.000000                  ?  183482.920      Assoc-voc           13.0   \n",
       "10  21.098085            Private  219614.280   Some-college           10.0   \n",
       "11  37.000000            Private  301132.400      Bachelors           13.0   \n",
       "12  22.000000            Private  131520.840   Some-college            9.0   \n",
       "13  21.000000            Private  362693.120   Some-college           10.0   \n",
       "14  51.000000            Private  300294.750        HS-grad            9.0   \n",
       "15  34.000000          Local-gov  188900.100   Some-college           10.0   \n",
       "16  41.000000            Private  262266.530        HS-grad            9.0   \n",
       "17  64.000000            Private  116378.625           12th            6.0   \n",
       "18  43.000000            Private   52628.355        HS-grad            9.0   \n",
       "19  21.000000                  ?  146625.230   Some-college           10.0   \n",
       "\n",
       "         marital.status          occupation    relationship  \\\n",
       "0         Never-married     Farming-fishing         Husband   \n",
       "1    Married-civ-spouse      Prof-specialty   Not-in-family   \n",
       "2    Married-civ-spouse               Sales         Husband   \n",
       "3              Divorced     Exec-managerial         Husband   \n",
       "4    Married-civ-spouse     Exec-managerial   Not-in-family   \n",
       "5         Never-married     Exec-managerial         Husband   \n",
       "6         Never-married      Prof-specialty         Husband   \n",
       "7    Married-civ-spouse        Craft-repair         Husband   \n",
       "8              Divorced   Machine-op-inspct         Husband   \n",
       "9         Never-married     Exec-managerial         Husband   \n",
       "10   Married-civ-spouse                   ?       Own-child   \n",
       "11   Married-civ-spouse        Craft-repair         Husband   \n",
       "12            Separated   Handlers-cleaners         Husband   \n",
       "13   Married-civ-spouse                   ?   Not-in-family   \n",
       "14             Divorced        Adm-clerical            Wife   \n",
       "15        Never-married        Craft-repair         Husband   \n",
       "16   Married-civ-spouse               Sales   Not-in-family   \n",
       "17   Married-civ-spouse     Farming-fishing         Husband   \n",
       "18        Never-married        Craft-repair         Husband   \n",
       "19        Never-married      Prof-specialty            Wife   \n",
       "\n",
       "                   race      sex  capital.gain  capital.loss  hours.per.week  \\\n",
       "0                 White     Male           0.0           0.0            40.0   \n",
       "1                 White   Female           0.0           0.0            50.0   \n",
       "2                 White     Male           0.0           0.0            40.0   \n",
       "3                 White     Male           0.0           0.0            50.0   \n",
       "4                 White     Male           0.0           0.0            40.0   \n",
       "5                 White     Male        4386.0           0.0            40.0   \n",
       "6                 White     Male           0.0           0.0            25.0   \n",
       "7                 White     Male           0.0           0.0            60.0   \n",
       "8                 White     Male           0.0           0.0            40.0   \n",
       "9                 White     Male           0.0           0.0            50.0   \n",
       "10                Black   Female           0.0           0.0            35.0   \n",
       "11                White     Male           0.0           0.0            40.0   \n",
       "12   Asian-Pac-Islander   Female           0.0        1887.0            30.0   \n",
       "13                White   Female           0.0           0.0            30.0   \n",
       "14                White     Male           0.0           0.0            40.0   \n",
       "15                White     Male           0.0           0.0            40.0   \n",
       "16                White     Male           0.0           0.0            40.0   \n",
       "17                White     Male           0.0           0.0            48.0   \n",
       "18                Black   Female           0.0           0.0            40.0   \n",
       "19                White   Female           0.0           0.0            25.0   \n",
       "\n",
       "    native.country  income  \n",
       "0    United-States   <=50K  \n",
       "1    United-States   <=50K  \n",
       "2    United-States   <=50K  \n",
       "3    United-States   <=50K  \n",
       "4    United-States   <=50K  \n",
       "5    United-States    >50K  \n",
       "6    United-States   <=50K  \n",
       "7    United-States   <=50K  \n",
       "8            Italy   <=50K  \n",
       "9    United-States    >50K  \n",
       "10   United-States   <=50K  \n",
       "11               ?    >50K  \n",
       "12       Nicaragua   <=50K  \n",
       "13   United-States   <=50K  \n",
       "14   United-States   <=50K  \n",
       "15   United-States   <=50K  \n",
       "16   United-States   <=50K  \n",
       "17          Poland   <=50K  \n",
       "18   United-States    >50K  \n",
       "19               ?   <=50K  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f\"{SYNTH_DATA_DIR}/{DATA_NAME}/tabddpm.csv\")\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surface-october",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffusion_models",
   "language": "python",
   "name": "diffusion_models"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
