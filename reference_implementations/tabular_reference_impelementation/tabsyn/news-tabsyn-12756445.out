Sun Jun  9 23:54:09 2024       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla T4            On   | 00000000:06:00.0 Off |                    0 |
| N/A   35C    P8    15W /  70W |      0MiB / 15360MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
/projects/aieng/diffussion_bootcamp/models/tabular/tabsyn/news
MLPDiffusion(
  (proj): Linear(in_features=192, out_features=1024, bias=True)
  (mlp): Sequential(
    (0): Linear(in_features=1024, out_features=2048, bias=True)
    (1): SiLU()
    (2): Linear(in_features=2048, out_features=2048, bias=True)
    (3): SiLU()
    (4): Linear(in_features=2048, out_features=1024, bias=True)
    (5): SiLU()
    (6): Linear(in_features=1024, out_features=192, bias=True)
  )
  (map_noise): PositionalEmbedding()
  (time_embed): Sequential(
    (0): Linear(in_features=1024, out_features=1024, bias=True)
    (1): SiLU()
    (2): Linear(in_features=1024, out_features=1024, bias=True)
  )
)
the number of parameters 10887360
Epoch 00467: reducing learning rate of group 0 to 9.0000e-04.
Epoch 00561: reducing learning rate of group 0 to 8.1000e-04.
Epoch 00589: reducing learning rate of group 0 to 7.2900e-04.
Epoch 00653: reducing learning rate of group 0 to 6.5610e-04.
Epoch 00680: reducing learning rate of group 0 to 5.9049e-04.
Epoch 00711: reducing learning rate of group 0 to 5.3144e-04.
Epoch 00746: reducing learning rate of group 0 to 4.7830e-04.
Epoch 00790: reducing learning rate of group 0 to 4.3047e-04.
Epoch 00811: reducing learning rate of group 0 to 3.8742e-04.
Epoch 00898: reducing learning rate of group 0 to 3.4868e-04.
Epoch 00925: reducing learning rate of group 0 to 3.1381e-04.
Epoch 00953: reducing learning rate of group 0 to 2.8243e-04.
Epoch 00983: reducing learning rate of group 0 to 2.5419e-04.
Epoch 01009: reducing learning rate of group 0 to 2.2877e-04.
Epoch 01039: reducing learning rate of group 0 to 2.0589e-04.
Epoch 01081: reducing learning rate of group 0 to 1.8530e-04.
Epoch 01102: reducing learning rate of group 0 to 1.6677e-04.
Epoch 01123: reducing learning rate of group 0 to 1.5009e-04.
Epoch 01151: reducing learning rate of group 0 to 1.3509e-04.
Epoch 01172: reducing learning rate of group 0 to 1.2158e-04.
Epoch 01205: reducing learning rate of group 0 to 1.0942e-04.
Epoch 01226: reducing learning rate of group 0 to 9.8477e-05.
Epoch 01264: reducing learning rate of group 0 to 8.8629e-05.
Epoch 01285: reducing learning rate of group 0 to 7.9766e-05.
Epoch 01325: reducing learning rate of group 0 to 7.1790e-05.
Epoch 01346: reducing learning rate of group 0 to 6.4611e-05.
Epoch 01370: reducing learning rate of group 0 to 5.8150e-05.
Epoch 01391: reducing learning rate of group 0 to 5.2335e-05.
Epoch 01412: reducing learning rate of group 0 to 4.7101e-05.
Epoch 01470: reducing learning rate of group 0 to 4.2391e-05.
Epoch 01491: reducing learning rate of group 0 to 3.8152e-05.
Epoch 01514: reducing learning rate of group 0 to 3.4337e-05.
Epoch 01540: reducing learning rate of group 0 to 3.0903e-05.
Epoch 01561: reducing learning rate of group 0 to 2.7813e-05.
Epoch 01582: reducing learning rate of group 0 to 2.5032e-05.
Epoch 01603: reducing learning rate of group 0 to 2.2528e-05.
Epoch 01635: reducing learning rate of group 0 to 2.0276e-05.
