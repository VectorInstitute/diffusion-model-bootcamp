Sun Jun  9 23:54:17 2024       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla T4            On   | 00000000:06:00.0 Off |                    0 |
| N/A   38C    P8    16W /  70W |      0MiB / 15360MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
/projects/aieng/diffussion_bootcamp/models/tabular/tabsyn/shoppers
MLPDiffusion(
  (proj): Linear(in_features=72, out_features=1024, bias=True)
  (mlp): Sequential(
    (0): Linear(in_features=1024, out_features=2048, bias=True)
    (1): SiLU()
    (2): Linear(in_features=2048, out_features=2048, bias=True)
    (3): SiLU()
    (4): Linear(in_features=2048, out_features=1024, bias=True)
    (5): SiLU()
    (6): Linear(in_features=1024, out_features=72, bias=True)
  )
  (map_noise): PositionalEmbedding()
  (time_embed): Sequential(
    (0): Linear(in_features=1024, out_features=1024, bias=True)
    (1): SiLU()
    (2): Linear(in_features=1024, out_features=1024, bias=True)
  )
)
the number of parameters 10641480
Epoch 00272: reducing learning rate of group 0 to 9.0000e-04.
Epoch 00300: reducing learning rate of group 0 to 8.1000e-04.
Epoch 00326: reducing learning rate of group 0 to 7.2900e-04.
Epoch 00374: reducing learning rate of group 0 to 6.5610e-04.
Epoch 00423: reducing learning rate of group 0 to 5.9049e-04.
Epoch 00466: reducing learning rate of group 0 to 5.3144e-04.
Epoch 00506: reducing learning rate of group 0 to 4.7830e-04.
Epoch 00553: reducing learning rate of group 0 to 4.3047e-04.
Epoch 00577: reducing learning rate of group 0 to 3.8742e-04.
Epoch 00598: reducing learning rate of group 0 to 3.4868e-04.
Epoch 00619: reducing learning rate of group 0 to 3.1381e-04.
Epoch 00640: reducing learning rate of group 0 to 2.8243e-04.
Epoch 00688: reducing learning rate of group 0 to 2.5419e-04.
Epoch 00709: reducing learning rate of group 0 to 2.2877e-04.
Epoch 00730: reducing learning rate of group 0 to 2.0589e-04.
Epoch 00753: reducing learning rate of group 0 to 1.8530e-04.
Epoch 00774: reducing learning rate of group 0 to 1.6677e-04.
Epoch 00795: reducing learning rate of group 0 to 1.5009e-04.
Epoch 00839: reducing learning rate of group 0 to 1.3509e-04.
Epoch 00893: reducing learning rate of group 0 to 1.2158e-04.
Epoch 00914: reducing learning rate of group 0 to 1.0942e-04.
Epoch 00935: reducing learning rate of group 0 to 9.8477e-05.
Epoch 00956: reducing learning rate of group 0 to 8.8629e-05.
Epoch 00977: reducing learning rate of group 0 to 7.9766e-05.
Epoch 01001: reducing learning rate of group 0 to 7.1790e-05.
Epoch 01022: reducing learning rate of group 0 to 6.4611e-05.
Epoch 01043: reducing learning rate of group 0 to 5.8150e-05.
Epoch 01064: reducing learning rate of group 0 to 5.2335e-05.
Epoch 01085: reducing learning rate of group 0 to 4.7101e-05.
Epoch 01106: reducing learning rate of group 0 to 4.2391e-05.
Epoch 01129: reducing learning rate of group 0 to 3.8152e-05.
Epoch 01174: reducing learning rate of group 0 to 3.4337e-05.
Epoch 01198: reducing learning rate of group 0 to 3.0903e-05.
Epoch 01219: reducing learning rate of group 0 to 2.7813e-05.
Epoch 01256: reducing learning rate of group 0 to 2.5032e-05.
Epoch 01277: reducing learning rate of group 0 to 2.2528e-05.
Epoch 01298: reducing learning rate of group 0 to 2.0276e-05.
Epoch 01319: reducing learning rate of group 0 to 1.8248e-05.
Epoch 01340: reducing learning rate of group 0 to 1.6423e-05.
Epoch 01361: reducing learning rate of group 0 to 1.4781e-05.
Epoch 01382: reducing learning rate of group 0 to 1.3303e-05.
Epoch 01403: reducing learning rate of group 0 to 1.1973e-05.
Epoch 01424: reducing learning rate of group 0 to 1.0775e-05.
Epoch 01445: reducing learning rate of group 0 to 9.6977e-06.
Epoch 01466: reducing learning rate of group 0 to 8.7280e-06.
Epoch 01487: reducing learning rate of group 0 to 7.8552e-06.
Epoch 01508: reducing learning rate of group 0 to 7.0697e-06.
Epoch 01529: reducing learning rate of group 0 to 6.3627e-06.
Epoch 01550: reducing learning rate of group 0 to 5.7264e-06.
Epoch 01571: reducing learning rate of group 0 to 5.1538e-06.
Epoch 01599: reducing learning rate of group 0 to 4.6384e-06.
Epoch 01620: reducing learning rate of group 0 to 4.1746e-06.
Epoch 01641: reducing learning rate of group 0 to 3.7571e-06.
Early stopping
Time:  892.7030222415924
